{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets\n",
    "#from bokeh.plotting import figure\n",
    "#from bokeh.io import show\n",
    "#from bokeh.models import LinearAxis, Range1d\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from numpy import vstack\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 6\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/silvio/MNISTData/'\n",
    "\n",
    "# transforms to apply to the data\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "# MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=True, transform=trans, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=False, transform=trans)\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "Epoch [1/6], Step [100/600], Loss: 0.2196, Accuracy: 95.00%\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-5b75e8022a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Backprop and perform Adam optimisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Run the forward pass\n",
    "        print(images.shape)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.96000000000001 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
    "\n",
    "# Save the model and plot\n",
    "#torch.save(model.state_dict(), MODEL_STORE_PATH + 'conv_net_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnnElEQVR4nO3deXhU5dk/8O8dCHvYw44GBWnFBQURiwv1pxXQilut9ldrF1+6aKu1ViNal7pRfbUWUBHUKi6ACggVEIGybxIgkJAAWVgSIAsJZA9JZu73jzkzmeXMZJJMMnOG7+e6uJjlzJw7k+Sb5zzPc54jqgoiIrK+mHAXQEREocFAJyKKEgx0IqIowUAnIooSDHQioijRNlw77t27tyYkJIRr90RElrRz586Tqhpv9lzYAj0hIQFJSUnh2j0RkSWJyBF/z7HLhYgoSjDQiYiiBAOdiChKhK0PnYioKWpra5Gbm4vq6upwl9KiOnTogEGDBiE2Njbo1zDQichScnNzERcXh4SEBIhIuMtpEaqKoqIi5ObmYsiQIUG/jl0uRGQp1dXV6NWrV9SGOQCICHr16tXooxAGOhFZTjSHuVNTvkbLBbrNrvh8Rw5sdi77S0TkznKB/un2I3h84V7M3Xo43KUQ0Vno9OnTePvttxv9ukmTJuH06dOhL8iN5QK9uKIGAHCqsjbMlRDR2chfoNtstoCvW758Obp3795CVTlYbpYLL7BEROGUmJiIrKwsjBw5ErGxsejSpQv69++P5ORkpKWl4bbbbkNOTg6qq6vx8MMPY8qUKQDqlzspLy/HxIkTcfXVV2PLli0YOHAglixZgo4dOza7NssFulP0D4kQUUOe/88+pB0vDel7XjigK5798Qi/z0+bNg2pqalITk7GunXrcPPNNyM1NdU1vfCDDz5Az549UVVVhSuuuAJ33nknevXq5fEeGRkZmDdvHubMmYO7774bCxcuxM9//vNm127ZQCciigRjxozxmCs+ffp0LF68GACQk5ODjIwMn0AfMmQIRo4cCQAYNWoUDh8+HJJaGgx0ERkMYC6AfgDsAGar6r+8thkPYAmAQ8ZDi1T17yGpkIjIj0At6dbSuXNn1+1169Zh9erV2Lp1Kzp16oTx48ebziVv376963abNm1QVVUVklqCaaHXAfiLqu4SkTgAO0VklaqmeW23UVVvCUlVAbALnYjCKS4uDmVlZabPlZSUoEePHujUqRP279+Pbdu2tWptDQa6qp4AcMK4XSYi6QAGAvAO9FZ1FpxXQEQRqFevXhg3bhwuuugidOzYEX379nU9N2HCBMyaNQuXXHIJhg8fjrFjx7ZqbY3qQxeRBACXAdhu8vRVIrIHwHEAj6nqPpPXTwEwBQDOOeecRhdLRBQJPvvsM9PH27dvjxUrVpg+5+wn7927N1JTU12PP/bYYyGrK+h56CLSBcBCAI+oqvew8i4A56rqpQBmAPjK7D1UdbaqjlbV0fHxpldQahjnLRIRmQoq0EUkFo4w/1RVF3k/r6qlqlpu3F4OIFZEeoe0Uu+aOHGRiMhDg4EujhVi3geQrqpv+Nmmn7EdRGSM8b5FoSyUiMhJz4Ij9aZ8jcH0oY8DcB+AFBFJNh6bCuAcY6ezANwF4PciUgegCsA92kKfePR/G4kokA4dOqCoqCiql9B1rofeoUOHRr0umFkum9DAiZmqOhPAzEbtuZmi9PtIRA0YNGgQcnNzUVhYGO5SWpTzikWNwTNFichSYmNjG3UVn7OJ5VZbJCIic5YL9LNgLISIqEksF+hO7EInIvJk2UBnQ52IyJNlA52IiDxZNtDZ5UJE5MmygU5ERJ4sF+jK3nMiIlOWC3QnnilKROTJcoF+1XmORRwH9mj+FbKJiKKJ5QK9V5d2AIAObduEuRIioshiuUBnVwsRkTnLBboTh0aJiDxZLtCdVyrimi5ERJ6sF+jsciEiMmW5QHfifHQiIk+WC3RnA51dLkREnqwX6OxyISIyZblAd2IDnYjIkwUD3TnLhZFOROTOcoHOLhciInPWC/RwF0BEFKEsF+hO7HEhIvJkuUAXo8+F89CJiDxZL9DDXQARUYSyXKA7scuFiMiT5QLdOcuFgU5E5Ml6ge6chx7mOoiIIk2DgS4ig0VkrYiki8g+EXnYZBsRkekikikie0Xk8pYpl/PQiYj8aRvENnUA/qKqu0QkDsBOEVmlqmlu20wEMMz4dyWAd4z/WwzPFCUi8tRgC11VT6jqLuN2GYB0AAO9NpsMYK46bAPQXUT6h7xa97pa8s2JiCyoUX3oIpIA4DIA272eGgggx+1+LnxDHyIyRUSSRCSpsLCwkaU636NJLyMiinpBB7qIdAGwEMAjqlrq/bTJS3wa0ao6W1VHq+ro+Pj4xlXa4LsTEZ3dggp0EYmFI8w/VdVFJpvkAhjsdn8QgOPNL8+0FgA8U5SIyFsws1wEwPsA0lX1DT+bLQXwC2O2y1gAJap6IoR11tfTEm9KRBQFgpnlMg7AfQBSRCTZeGwqgHMAQFVnAVgOYBKATACVAH4V8kq9cJILEZGnBgNdVTehgYaxOuYQPhiqogJxnSnaGjsjIrIQ654pykQnIvJgvUBnJzoRkSnLBboTZ7kQEXmyXKA7G+jsciEi8mS5QOe8RSIic9YLdAMb6EREniwX6M5ZLuxzISLyZL1AZ5cLEZEpywW6E9vnRESeLBfonOVCRGTOcoEe41xtkYlOROTBsoFuZ54TEXmwXKA7+1zsbKETEXmwXKDHcJYLEZEpCwa6s8uFLXQiIneWC3RxdbmEtw4iokhjuUCvn+US5kKIiCKM5QLdiV0uRESeLBfoMTz3n4jIlAUD3fG/nZ3oREQeLBfowhOLiIhMWS7QnS10XoKOiMiT5QKdLXQiInOWC3TAMRedi3MREXmyZKDHiHAeOhGRF4sGOuehExF5s2SgC4R96EREXqwZ6MJZLkRE3iwZ6OxDJyLy1WCgi8gHIlIgIql+nh8vIiUikmz8eyb0ZXrvk2eKEhF5axvENh8CmAlgboBtNqrqLSGpKAgxIuxwISLy0mALXVU3AChuhVqCJuAsFyIib6HqQ79KRPaIyAoRGeFvIxGZIiJJIpJUWFjY5J05Tixq8suJiKJSKAJ9F4BzVfVSADMAfOVvQ1WdraqjVXV0fHx8k3cYEyM8U5SIyEuzA11VS1W13Li9HECsiPRudmUBOLpcWnIPRETW0+xAF5F+YqyYJSJjjPcsau77BuIYFGWiExG5a3CWi4jMAzAeQG8RyQXwLIBYAFDVWQDuAvB7EakDUAXgHm3h/hARnilKROStwUBX1XsbeH4mHNMaWw1XWyQi8mXRM0U5y4WIyJtFA104D52IyIslA52zXIiIfFkz0Lk4FxGRD0sGekwMB0WJiLxZMtAdF7hgoBMRubNkoMcIeFoREZEXSwY6TywiIvJl0UBnHzoRkTdLBjovQUdE5MuSgc4LXBAR+bJkoLOFTkTky5KBLsIWOhGRN4sGOme5EBF5s2SgxwjAmehERJ4sGuhsoRMRebNkoLMPnYjIl0UDnbNciIi8WTLQY9hCJyLyYclAF/ASdERE3iwZ6DEiUM5yISLyYMlAFwHs9nBXQUQUWSwa6GyhExF5s2SgOwZFw10FEVFksWSgC4TroRMRebFkoDsuEh3uKoiIIos1A114kWgiIm+WDHSAfehERN4sGeiOeehEROSuwUAXkQ9EpEBEUv08LyIyXUQyRWSviFwe+jI9xfAi0UREPoJpoX8IYEKA5ycCGGb8mwLgneaXFZiwD52IyEeDga6qGwAUB9hkMoC56rANQHcR6R+qAs04WugtuQciIusJRR/6QAA5bvdzjcd8iMgUEUkSkaTCwsIm75CXoCMi8hWKQBeTx0zjVlVnq+poVR0dHx/frB2yD52IyFMoAj0XwGC3+4MAHA/B+/oVwwtcEBH5CEWgLwXwC2O2y1gAJap6IgTv6xcvQUdE5KttQxuIyDwA4wH0FpFcAM8CiAUAVZ0FYDmASQAyAVQC+FVLFevEeehERL4aDHRVvbeB5xXAgyGrKAhsoRMR+bLkmaK8SDQRkS9LBjrPFCUi8mXRQOc8dCIib5YMdAH70ImIvFkz0NmHTkTkw5KBzj50IiJflgx04UWiiYh8WDLQHScWMdGJiNxZMtBVgfzSM+Eug4goolgy0BckOVbrzS+tDnMlRESRw5KB7lRYxlY6EZGTpQOdiIjqWTrQxezSGkREZylLBzoREdVjoBMRRQkGOhFRlLB0oIvp9amJiM5Olg50IiKqx0AnIooSlg50TlskIqpn6UAnIqJ6lg7005W14S6BiChiWDrQ752zLdwlEBFFDEsHOhER1WOgExFFCQY6EVGUYKATEUUJSwb6lUN6hrsEIqKIY8lAtysvEE1E5C2oQBeRCSJyQEQyRSTR5PnxIlIiIsnGv2dCX2o95jkRka+2DW0gIm0AvAXgRgC5AHaIyFJVTfPadKOq3tICNfpgC52IyFcwLfQxADJVNVtVawDMBzC5ZcsKLKF353DunogoIgUT6AMB5LjdzzUe83aViOwRkRUiMsLsjURkiogkiUhSYWFhE8p1+MP4oU1+LRFRtAom0M3WNPTu89gF4FxVvRTADABfmb2Rqs5W1dGqOjo+Pr5RhbprG8NlFomIvAUT6LkABrvdHwTguPsGqlqqquXG7eUAYkWkd8iq9MJlc4mIfAUT6DsADBORISLSDsA9AJa6byAi/UQcMSsiY4z3LQp1sWbST5S2xm6IiCJeg7NcVLVORB4CsBJAGwAfqOo+Efmd8fwsAHcB+L2I1AGoAnCPautMRVmRmofv9+/aGrsiIopoQc1DV9XlqnqBqp6vqi8Zj80ywhyqOlNVR6jqpao6VlW3tGTR7heHnr4moyV3RdRq6mx2vPh1Gk6Wnwl3KWRRljxTtEOsJcsmCmjtgUK8t+kQnlmSGu5SyKIsmYx9unYIdwkUIU5V1KD8TF24ywgJ5wlztTaeOEdNY8lAp8ihqvhq9zHU2uxh2f9lL6zCD15ZE5Z9txSeCE1NxUCnZlmekodHFiTjrbWZYauhtDo6Wuj1I0NMdGoaBjo1y6nKGgBAQRkH8prLmPnLFjo1WVQHuqri0MmKcJdxVmAINV+RMbuFH2X4bcwoxMfbjoS7jEaLikDfcbgYAGC3K3YeKXY9/t7GQ/jh/65D6rGScJUW9XjWbugkLkoBAGQWlIe5Errv/e/wt6+sN9soKgL9J7O2InHhXszZmI0739mKzZknAQA7j5wCAOQUV4azvLME25WhYjbAvD+vFF8k5ZhsTVQvKgIdAObvyMGcjdkAgGOnqhrcXlUxe0MWSqpqW7o0HzV1djzwURIO5JW1+r5DTUzXbqPmMFvvf8KbG/HXL/eGoRqykqgJdAA4We4YoHP+QmiAVuOmzJN4efl+/PTdrTh/6nIcO93wH4FQ2ZN7GqvT8zF1cUqr7bOlOLtczPrQlyQfi5o54q3JzoMdaiLLBvr58f4vcmEz0mXlvny/29TUOQ5r9+eVwWZXrE7zv623L5JysCXrpOt+UfkZJCQuw4IdR4N6vTP8oqFt6/wavAM97XgpHp6fjCcWslXZWBxgpqaybKA/csMFfp+za31gO+8Xea2PEeM1mtfQWmJ2u2L6mgwUlFbjr1/uxc/mbHc9N+rF1QCAF79OD6p25768awil/NJqJCQuw5LkYy22DwD4aKtjJoD30VBVraNlfrwVj3yiRSuta0dRyLKBfssl/f0+Z7erR8DMXJuJUS+uxomS+nDxHnj6Kvk4lqec8PueW7KK8MaqgxjzsudZiaeNedgAcCbIsyVdh9Qt2ERPOuwYEH54fjJScoOf5aOqrkAZ89Jq3PVO4HXWnMsX+2YQ51Q3lc0iH9qcDdm47/3tDW9IrcaygS4BWrfT12Rg2d76cHaGTl5JteuxKR/v9HhNcs5p/OHTXR4r3dntiuteW4sb31iPBX5mGGzMqO96cT8q8FZTZ8dtb23Gtuz6ZeJbq8sloyD4wdfhf/sGE/+1EYDjZKEkY6ZQY0X6dMbiihp8k5oX7jJM2S3Sif7S8nSPn/+WcrL8DPbmnm7x/UQDywZ6IEUVNXj08z0+jx/IK8O767OQXeh/nu8PX1vnul1js+NIUSUyCsrxnz3HTbcPFOLuck5VIjnnNJ5clOI6emitU9ZtjQiImjo79jdh9s3+vDIkJC5DRr7na517LqmsxecRNO3ugY924Hef7ERxRU3DG7cya8R567ll+ibcOnNzuMuwBEsH+u6/3dio7RMXpeCVFfsD/nCUnalD7qlKfLb9KKprbQHfz2y+cMWZOtPpiO4NVucRdfqJUmQVlqOmzo43Vh1EVU3g/TWGe5eT2RF8dmE5ztQFv79TFTV44su9fj+TFOPkLWer1/X1Gjt/7Ms9ePzLvUg7HtwVpsqqa7HraNOODoJxtNjR/Vbn9T3ML63Gz+Zs8+hKa22R3uOiqi26dk/qsRKPcYS80uoAW0eWcI9/WDrQO8S2adLrGppKd/8H32Hq4hSM/PuqgNtNX5Ph05r69Yc7cNObGwJ+Y+fvqG+pZhWUY8GOo5i+JgO//WQnKhoxzW/tgQJsMU6iqjD+EJnx7pPdmlWE619fH/BMuIU7cz3u/++3B7AgKQcLd+X6eYWDXR0/1OknHH/UnHt2rvUSzB8Rm10xeeZm3PH2FlTWtO60x3fXZ2NLVhG+3Bn46wxWVmE5Vu5rXNeO2Tx0J1VFVmE5CsrCF3JJR07htZUHXPfrbPagjwLLqmvx6IJkv+d/rD9YiFtmbMKn24ObMdZc3pMl/MksKPM5+vSWkV+GIU8uDzhjLqe4MqQNN2+WDvR2bVum/GDXfzl2usonuLcfciw9sOOweevy0MkKj+4buyrOGN02Gw4W4o/zdgNwfOM3ZhQG3P+v/r0DP3vPMSh197tbcfU/1rrOinU/4ccZEGXVtdh3vAT3ztkGAPg8Kddvf+1fvqjvslq5Lw+r0x0/pGdqA3cx2VXxyfajrjn2ro+nES2X1789gGzje9BSa4M7v297ckta9ApB/+/19fit13iN0x8+3Wn6y+/8fuWXVvscBao63nPMS2taNBgCqfXqZhz61ArcMmOT6bYrUk4gIXEZThldW//efBiLdh/De8ZJgN6OFjm+7/vzmn6t4G3ZRUF1hS7cmYtRL64OatLADW9swI3/3BBwG+cR5bdpvn/AS6trkZC4DNe8uhZTPk5qcH9NZelAbxPTMiNvQXc5B9ju7ne3YmtWEca/ttbxA11p3iKps6vH9MVdR08h7Xgprnl1Le57/zvX9MO/fL4HM9ZkoLTa/H32GV0Z17y6Fiv35eHBz3bVfz3GF3T721tw83TPX7x3N2Tj0c+TA7b4fvvxTuSXOkLv71+n4ZXljumZZkchjtZ5/S9jitc6Os7B7NRjJVidlo8fvLIGR4s8jyw8BtrcdvHogmRc8+p//dbZGEVGwPzP3CRMMgaBAeCDzYeCfo+dR04hIXEZMhsx6OxueUoeHpjr+8tttwPVtTZc+fIan3n87q3333+6EzuPFGOp0UDIK6nGmvTA51OkHivBh434Gr3V2ex4f5Pv6/1drP09Y9usAONWHoJYcfLWmZvwhJ+zZlOPleCe2dswbcX+Bne12TiX5EADLe9gJCQuw9+W7ANgnkvuEzJaciDZ0oEebot2Hwu48FdmQRkOG2H15uqDptvY7Ar37//pylpMml4fMFca0yQX7srF66sO4pLnvvXbunHybhF+uesYrnttremiT2+vzcSiXcfwp3m78eiC5IDv6/Tuhmy8+s1+1Jn85bMrEMzf2VtmbMIDc5NwvKQa1762Fot25bpao/5myCzafQw5xVX484JkJCQu8+jPd95WVfxszjbc9M8NqK614X/mJvmEifcfooKyMxg6dblHd1egWVROziOtDQcb/wsaqEvOrur6pV+0y/M8Avcjlk0ZJ3HnO1vxJ+Oo7o63N+M3HwVu/d0yYxOe+09ao+t1+mJnLtbsL2hwu9xTlTiQV+b36/T35btOVAMwY02Gz4qHTy5Kwd7cEr+zzpzLOR/ID6KF34SDv0DTeJ1HBWbnl7TW4HvbVtlLFHOeWNMQf3+V/7nqoCv0g/XisnSMOreH6/7b6wIPUO3JOe33uTIjxLZlF/vdxszb67IwYkA3n8cV6rO+i3v/atrxUowc3N3ndY9+vgdHiirx5xsvwF63Q2CF4mB+GRa4jTss3u0IuVK3ftjv/e0bHJ52M1anF2BLlmNq6Jask1iVlo+qGhs+eeBKAI6W0liTKxzV2RVH3L4PmzNP4vbLBqJn53Ye272/6RAuHdQNoxN6us4WDtTn7U+gPuc6u/qdiXXP7K2mj2/JPInjRitwf14pvteva8D9ZxaUYeZ/M/HLcUPwvX5xrvGo7MJyTF2cgvfvvwKd2/vGQ7BjPFf/Yy0A4PJzugMAnv4qFQVlZ/CjC/sG9fqDeWX4zKsfPSFxmcf9WpsdB/PLPH4OnWGaWVCOfcdLMLxvHGyqaN/W/3hbY47zg5nG6x7oNrvikudWoqKVusfYQm9BzkOwQBob5k63v13fUnj1mwMBtmw5qcd9j07eWpvl00I/frrK1RiaujgF09dkmL5ffmm1aZ/+j/65wfQw3/uiGgmJyzxCfkmyowUt4uhXfX/ToYB9s+4Nq//uL8DlL6zy6F89VVGDF75Ow12zHKF6MN8RutknK1x1v7QsDVe9sgYJicsw/7v6QPL+utwHqs360VPdZgMNnbrcdXuPn/5e51gK4FjIq7KmDn/9Yg9W7sszXdf7hjc24Kvk47jtrc24a1b9z9K0FfuxLbu4wfGbQNz7/Wts9UtsFFfUuCYEeA/UqyreWZeFp42B+mD+RL68PB03T9/k8cfP+T3MLz2Dm6dvwsR/bcTwp78BAKxKy8cLX6e5/igtMhoGecZYRU2dHQmJy/D4l75Tnhvj421HXI2omjp7q4U5EAWB7mwBUOt7Z11WUNt5t0bfWGXe/WRXxYz/eh5tBJppZDYQ5z6DyRnoGzNO4p7Z2/DC12kBl1swe+7HMze5Atc9NN19tv0oZvw3E4VlZzBn4yGcMFrKzvXNAeA8t1AGgKyC+oH3B+YmYfFuz1k1KW4n0ph1bQV6HADmf5eDL3bm4rcf78TfvkrFjsPFKPAz/S/1WP0fj9g2jkgwG4wuKK3Gi8v8L2/x4teOrhz3rHZ/b4/avQZ7P9l2BP/4pr7fO5gTif69+TCA+kX5ACDXa6XVDKObsaSyFv8zNwnvbzqEP3y6y+Nn8rWVB/D04lR8Yvzh+zyp4RlOtTY7Ptt+1O+R1uS3HFOj6+yte61dywf6x7+5MtwlkBfv1te8HQ3P6QcAmx34p5+xhmA9uzTwUVGgQL/pTfNZDN8ZF1DxN/AHOOq+4qXVAfc9bcV+5JVU40/zdnuMkwDAnxd4tgqbeuTm5N0N9JNZW32WrfCWWVCGZcbyF3+ctxsJicuwNav+zOY/zd8d8PXOAdAjRQ3PEpuz0bHt6coajwFFp8bMbnL206efKMXjfgZLL/37t67b6w8W+kyfXZCU45pt5i6nuNKnqyevpBrDnlqBqYtT8Nl3R/2OE9jsiv/vpxHQUizfh+7ez5f50kTU2hTff+abMFZEn2zz7Pt8d33gQVynhua4h8K7G4I7qnBnsyue/49n4DTlxJpZ67Mwa33j998U721s3EyWbdlFmPed79zvdQcLMGJgV0xdlBLUOMve3NNBn9WZkLgME0b0a1SdZhSOkL7/g++Cfk21yfRbs7GQa15d6/OY+/kepVW1fmfF2ezqMR7k7lRFDXp4jc+EgoTrzKbRo0drUlJo5mMu3XMcsTGCiRc7Fuzy/otK1By//EECPtxyONxlhEW7tjFBL28RLu/eNwoLd+bi20YsgX3D9/tgdXrDs3XMxHVoizJj2Y5xQ3vhhckX4frX1/tsd82w3n4nQ5zbqxPW//WHTdq/iOxU1dGmz0VDoHsb9tRy1yHbq3dd4vcwjIgoXA5Pu7lJrwsU6JbvQzez+YnrXbfvHj0YSx8ahynXnme67V9vGt5aZRERtaioDPQ+XTt43L9kUHc8euMFeP7WET7bXndBfGuVRUQEAJh4UfPHDswENSgqIhMA/AtAGwDvqeo0r+fFeH4SgEoAv1TVXT5v1IruuGygxxSmDrFtcP8PEnBur0749Yc7XAMZ3TrGmr5+2h0X4/w+XXBFQk8UV9Tg8hcCL9QVCt06xqJ92xif+dVEFF1iWmjZkgZb6CLSBsBbACYCuBDAvSJyoddmEwEMM/5NAfBOiOtstDd+OhKf/+4qn8fHD++D1Odvwt8nj8CzP74Qg3t2wnUXxOO83p2R9fIkPH3z9wEAQ40wB4Cendvh2z9fCwAY2L0jZtx7Gc7r3Rl3Xj7I40zCxyf4dt989OsxQde859kfYeMT5gMlj9wwLOj3CdbY83qG/D2JqGGxLRToDQ6KishVAJ5T1ZuM+08CgKq+4rbNuwDWqeo84/4BAONV1e813VpyULQ5VBWZBeUY1jcu6Nd8vfc4LhnYHYN7djSWShVU1dbhlksGILZNDCa8uQE2u2LVo9cBAJIOF2Nony7o3qkdUnJLMH/HUfzg/N642e2yerU2O4Y9tQIA8NPRgzHtzovx5uoM3H3FYHy1+5hr+dI7Lh+IV+64GO3btkFlTR0e+CjJdeo7AHyvXxzGDOmJHYdPYf6Usbj0ecd83EE9OmLdY+Nx/evr0aNTLJ6ffBH2nyhF4qIU9OrcDiMGdsOGg46zBd+4+1K8tTYTWYUV+OP1Q10n/0weOcB18g4A/OXGC/C6yUlDIwZ0xfC+ca4z88y8csfFeNLtRBxvD/1wKG4dOQC/+WgHJl3UH9deEB/0HN+49m1dSxw05Ibv98HkkQNdq1421nnxnZFdGNxqnQDwk1GD8EWIluodN7QXNmcWNbxhK/rqwXG47a3gpjGOG9oLR4srkVPs/zq0gWaOWMmOp25AfFz7Jr22WbNcROQuABNU9QHj/n0ArlTVh9y2+RrANFXdZNxfA+AJVU3yeq8pcLTgcc4554w6ciS4dVCigaoGteCTO5tdITA/PKuqsaFDbEzA98wvrUZch7bo1C740w2OFFWgf7eOaNc2BqcqatClQ1vX2YMH88swrE8Xj30WV9RgdVo+brqoH7p1jMWx01VYknwME0b0Q43NjnN6dnLt/5vUPFw8qBt6dW4Huyo6tWuL6lobFuzIwX1jz0VMjKDOZsfLy/ejTQxwzbB4DOndGYN7djKtdUnyMXTtGIvxF8RDRFBrs7tqPZBXhn7GWEq3TrFQVazcl4frLuiD9LxSXH5OD9TU2VFaXYuendrhzdUHMbRvHG69dIDr6+rRKRbVtXacqbOhxmZH+oky1NbZ8cySVDx8wzD8e/NhXDqoOyZfNgBDendG+olSjBzcA2XVtViTXoDbLxuIrdlFqLMrrhsWjwVJR3HRgG64eFA35BRX4cIBjvVWztTZcLSo0qcRcbSoEp3bt8HhogoM6N4RsW1iENehLfJKqtGzcztkF1Zg8e5jOLdXJ0y6uD/6Gl9vSWUtDhaU4bLB3ZF9sgKnKmqQnHMah4sqcE7PzgCA9zZmo7rWhm8eudb1+drtiuMlVbDbgf7dO+DQyQrM3pCNk+VncPtlAwEA58d3QbeOsYiPa4+qGhs6t3fU0zuuHYrKazC4ZyeknyhFXAfH93ZoH8fXVGez4x/f7MfVw+LRrWMsSqpqkX6iFD8ZNQinKmsRI8B58V0AAB9tOexYCmB9Fn41bgh+e+15qLMrqmpt6NohFqvS8lFUfgbjh/dB906xmLooBRcO6IphfeNQVWNDjADXDY/H13tOwGZX3H3FYBzIK0P3TrGotdnxmw+T0KdreyQdPoUzdTbceukADOsbhwv7d4XNrhjeLw6z1mfh7tGD0baNoH+3jliafAxr9hfg6ZsvxPB+ccgprkRmQTmuOr8X6uyKORuycW6vTli4KxfP3DICCb07YeW+fMTGCDZmnsQfrx+K/t06Bv17GEhzA/0nAG7yCvQxqvpHt22WAXjFK9AfV1XzhaARuS10IqJI1txpi7kABrvdHwTA+wKbwWxDREQtKJhA3wFgmIgMEZF2AO4BsNRrm6UAfiEOYwGUBOo/JyKi0Guwc1VV60TkIQAr4Zi2+IGq7hOR3xnPzwKwHI4pi5lwTFv8VcuVTEREZoIaLVPV5XCEtvtjs9xuK4AHQ1saERE1RlSeKUpEdDZioBMRRQkGOhFRlGCgExFFibCthy4ihQCaeqpobwBWOf/XKrWyztCzSq2sM7Raus5zVdV0mdiwBXpziEiSvzOlIo1VamWdoWeVWllnaIWzTna5EBFFCQY6EVGUsGqgzw53AY1glVpZZ+hZpVbWGVphq9OSfehEROTLqi10IiLywkAnIooSlgt0EZkgIgdEJFNEEiOgnsMikiIiySKSZDzWU0RWiUiG8X8Pt+2fNGo/ICI3tWBdH4hIgYikuj3W6LpEZJTx9WWKyHRp7GWXml7rcyJyzPhck0VkUrhrFZHBIrJWRNJFZJ+IPGw8HlGfa4A6I+ozFZEOIvKdiOwx6nzeeDzSPk9/dUbU5wnAcWk0q/yDY/neLADnAWgHYA+AC8Nc02EAvb0eexVAonE7EcA/jNsXGjW3BzDE+FratFBd1wK4HEBqc+oC8B2AqwAIgBUAJrZSrc8BeMxk27DVCqA/gMuN23EADhr1RNTnGqDOiPpMjffsYtyOBbAdwNgI/Dz91RlRn6eqWq6FPgZApqpmq2oNgPkAJoe5JjOTAXxk3P4IwG1uj89X1TOqegiO9ePHtEQBqroBQHFz6hKR/gC6qupWdfw0znV7TUvX6k/YalXVE6q6y7hdBiAdwEBE2OcaoE5/wlWnqmq5cTfW+KeIvM/TX53+hO1n1GqBPhBAjtv9XAT+QW0NCuBbEdkpjotgA0BfNa7YZPzfx3g83PU3tq6Bxm3vx1vLQyKy1+iScR52R0StIpIA4DI4WmsR+7l61QlE2GcqIm1EJBlAAYBVqhqRn6efOoEI+zytFuhm/U3hnnc5TlUvBzARwIMicm2AbSOxfsB/XeGs9x0A5wMYCeAEgNeNx8Neq4h0AbAQwCOqWhpoUz81tUqtJnVG3GeqqjZVHQnHdYjHiMhFATaPtDoj7vO0WqBH3MWoVfW48X8BgMVwdKHkG4dXMP4vMDYPd/2NrSvXuO39eItT1Xzjl8gOYA7qu6bCWquIxMIRkp+q6iLj4Yj7XM3qjNTP1KjtNIB1ACYgAj9Pszoj8fO0WqAHc8HqViMinUUkznkbwI8ApBo13W9sdj+AJcbtpQDuEZH2IjIEwDA4BklaS6PqMg53y0RkrDEa/wu317Qo5y+04XY4Ptew1mq87/sA0lX1DbenIupz9VdnpH2mIhIvIt2N2x0B3ABgPyLv8zStM9I+TwDWmuXiGEfAJDhG7bMAPBXmWs6DYzR7D4B9znoA9AKwBkCG8X9Pt9c8ZdR+AC0wY8RtP/PgOAyshaNl8Jum1AVgtPGDmgVgJoyzi1uh1o8BpADYC8cvSP9w1wrgajgOkfcCSDb+TYq0zzVAnRH1mQK4BMBuo55UAM809fcnTHVG1Oepqjz1n4goWlity4WIiPxgoBMRRQkGOhFRlGCgExFFCQY6EVGUYKATEUUJBjoRUZT4PwnfxnNrcmPuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(loss_list, label='train')\n",
    "#pyplot.plot(acc_list, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkLElEQVR4nO3deXxU9b3/8dcnC1kgJGRhS4AABgRZJSKKoAiy2iJt9arVXu2C9mrVtlrB1u4Ltb/2Wut2vVevt7e9em1FqxYrvRXrWhFkdwORJUQhgmELgRC+vz9mYWZykkzCxMkZ38/HI4/MnHNm5jMnyTvf+Z7v+R5zziEiIv6XluwCREQkMRToIiIpQoEuIpIiFOgiIilCgS4ikiIykvXCxcXFrry8PFkvLyLiSytXrvzQOVfitS5pgV5eXs6KFSuS9fIiIr5kZlubW6cuFxGRFKFAFxFJEQp0EZEUoUAXEUkRCnQRkRTRaqCb2QNmtsvM1jez3szsDjPbZGZrzezUxJcpIiKtiaeF/iAws4X1s4CK4Nd84J4TL0tERNqq1XHozrnnzay8hU3mAr91gXl4/2FmBWbWxzn3fqKKbI83399H3ZGjjBtQ2GTd1t0H2banjkkVgbH5b1Tv41DDUd77sI7pp/TimfUf8LlxZZhZ+DHHjjkeem0br27ew3VTK3hl824+OniEk3vnMf2U3gA457j50bUcPNLIG9X7GFzSlW+cN5RV2z/ipJJubNl9EOega1YGuV3SefatXcwdU8r2PXUM7tmNMf0KcM5x1X+vpHrvIUaWFvDE6h3MHtmHX1w4mifXVDN5SAnPrP+Abz26FoCFs07mktP70z07k/U79nLFfy7n8gnlLF5VxbgBPbh+agW3PLaOgcVdmTK0J//+wmbWbN/Lry8ew/RTevPm+/vYc/AI7++tZ2ivPBavqsI5mFRRzKpttaypqqXxmOPac0/id//Yyq8uGsMtj60jKyOda6YMZsm69/npkrcYXZbP4J7dWPz6DiZVFDN7ZB8WLl7H6QMLuWBsKWedVMw3/7CG9z48yGfGlrJ6ey3/dFo/xvQr4JdL3+E3l4zl/hff48GXt9A7P5uVWz/ikvH9eGzVDgYWd+PCcWV8eOAw79Yc4AtnlHPk6DFqDhzmwZe28KWzBpKfk8lL737IoJJuAOw71MC+Qw3MHNGbj+qO8MUHVzCsT3cOHj7Ktj114Z/rZ08t49HXqwD40QUjyEpPoyQviysffA2AwSVdcQ5qDhxmf/1Rz9+12SN7s2TdB/zzGQP48qRBXHb/q2zdXcfZQ0rompXOknUfUFqQw+6Dh6lvOEZ5US5bdgdquO1zo/jWH9cyfmAhq7Z9xLRhvXh6/QcADCruyqCSrpTkZVFdW8+Ro8f4ybwRzLj9eRoaA9Ne9+6ezbThPTnrpBL++sZO3t97iCG98njw5S2M6VfAR3VH6JKeRu/8bFZvq6VXfjabdh0I117YtQuvLDyX+b9dyd/fqYl6X3NG9eHPawN/xpdPGMCQ3nn8+v828uGBw5iBczC6XwFrttdy1dmD6JWXTW3dEZ5a+z4/njeCg4cbOW94L/64soob/7AGgAFFuWzdXYcZnDagkOVb9nD6wEK+OX0oW3YfZGivPK596HW27zkUriMz3bju3Ar+sLKKK84sZ/X2Wp5YUw3A2UNK+Ps7Ncwd05eNOw/QvzCXt3fuxww21xwEICsjjcNHj3n+7ADysjK47IwB3PPcuxTkZjK5oiT8/ADjBxaytqqW+oamz5GVkcaXJw3krmXvkpFmHD3mmDOqDyP65vPzv7wVtW2/whxunnkyj6+q5p7LTiUzPfE93hbPfOjBQH/KOTfCY91TwCLn3IvB+38DbnbONTlryMzmE2jF079//3FbtzY7Pv6ElS/4MwBbFs1pdV3ofqR/u3wcM4JBDfDIa9vDIRpr409mkZmexrK3doWDoD22LJrDs2/t5IsPNj3h6rF/OZN5d7/MuSf35Nm3dkWtmz68F/d9odLzfbT2em19TF5WBvsPB4LtvOG9+OsbO9v0+OZcMKYvj6+ubn1DSbi5Y/rypw7a9+/+dDaDb1nSIc/tZzdMq+CGaUPa9VgzW+mcq/Ral4h/EeaxzPO/hHPuPudcpXOusqTE88zVE9J4zLG/viFq2dHGY02WhezcV8++Ztbt2lfP9j11fLC3HoCtew42+7p7Dh7hjep9HDjs3YKL1/76hqiWSaSNwVbVhuq9TdatrdrLm+/va/PreT1Xa/ZHvMfn3t7VwpZtozBPno4Kc4D3PjzQ+kafQB8eONwhz5uIFvq/Ac855x4K3n8bOKe1LpfKykqX6FP/Fy5ex0PLt7HxJ7Oo+PbTUes2/3Q2aWnGsWOOQW1sMTx+zUQuuOulVrcbWZrPuh1tD0kR+WT5/On9+cm8ke16bEe30J8AvhAc7TIB2Jus/vPFwb7QxmNN/0k1Bv9xNbbjknvrqmrj205hLiJx8IiohGj1oKiZPQScAxSbWRXwPSATwDl3L7AEmA1sAuqAKzum1Pj9z6vbmiyLbbG3xa1/2nAi5YiIRHlo+TZ+9pn2tdBbEs8ol0taWe+AaxJW0QkIDUr54VNvJLcQkRQxYVAh/Xrk8oeVVckuJaUUde3SIc+bEmeKrtz6Eau312Kex2dFOtagkq7JLqHDLJg1jPEDmw797Uz+ePUZvPWjlk6VaertH7dt+0RLT+uYrEqJQP/sPS9zwV0vYcpzSYJzh/ZMdgnNystu2yUPJp5UFHV/8An+s5oZMfS3o1T0yiMro21R1qUDxoB7+fJZAz2XL5x9coe8XkoEekg7jndKO/QrzGlx/ZxRfdr93F7nDUTa+JNZ7Xreq84e1OpzN2f+5EGey684sxyAvgU5bFk0h/d+Nju8Lva1QsF62YT+bFk0p9UW4hPXTmxTvWu+Oz18+7zhvfjBp08B4IIxpWxZNIcti+aQmd60xXPXpaeG129ZNIfe3QM/29s+N4oti+aQl50ZdYJdayKfa8uiOdx7+bgW+4qXXDcJgKG98sjJTAfgHwunsmXRHO64ZGx4u8KYLorIfZOfE6gx3v2Vk5neZPtQvc29n+bcNGNoi+u/c/5wz+XzxpbFVWtb+T7Qj0ScAXaooTGJlXxyjC8vanF9Zgd9nARIbyVcmvsoe7Qx+r99cbesuF/zlL7dPZcPDy4Pdbm0FHyhM1hP6ZsPQEZaYv70+hfmApCVefz5xvYvCNc0ovR47eee3PSTxICi3Kj7DY2Bv6fI8C8PbtPeT8CxrxGpIDcTgDMjPhmEfoaRLzeporjJY0eX5TdZNrxP9M+qi0fLPZG/nhU9uyXuyRIgaZegS5S6Iyd2Mk9H6JKexpHG5k81jvX50/vze4+ROV7Glxfy08+MZNqv/u65/mefGcnCxevifu2QV2+ZSnXtIebd/XKr214zZXD4dPnbPjuKMf0LyM/J5PWtHzG8b3fu+NumqO2Xfn0y33hkNet3BE5+6pmXxa79gRMrnrlhMg+8+B7/u2I7c0YGWvYvLTiXST9/1nNoV1qa8crCc8lMT2PFlj1c/bvXo9Y/ff0kbvrDGtZURQ8hDQ1lfWnBuezcV8+GHXvDo5f+5yunA4GQvejfXgHgz9edRXG3LGrrGhjaO4/JFSXUNTQycdGzALz27WkUd+vCmH4FDOmVF36dp752FjldAi3NF2+ewu9f3cY9z73LxMFF3PbZUQzpFQgAr1AZ06+A1dtro5a9fut5bKjey+X3Lwdg8b+cyWeCP6OlX59M/8JcPthbT3awdQtw1eTBpKcZz9wwOfx6AL++eCybaw6Sl53BpNuWATCiNDoUjx47Ft4XIZXlhSz9+mTKi7qy/aM6jjY6Ztz+fJP6X/v2tKZvCjhzcDFPfe0scruk8/iqHdzx7Cb+qbIf35wxhJ552fzfN85mQFEuDy/fDkQEenAfje5XwG2fG8UN04Yw5f89F37e//nKBPYcPBL1Wo9cfQa1dUc46+eB97f8lqnUNxxj76EGGhqPcf5vXiQtYuev/M60qN+zF2+eQuMxR+MxF/45Aqz4zjSqaw9RXtyV92vrw+8/NO3HC9+awn3Pb+a//7GVq84exJCeeeF/oC98awoNjce4/P7l7Kg9xD2f77j5C30f6EdamKMhWYb17c6amD/MlrTlv3yfgmxOamH7S8b3b1eg9+qeTa/u2XFtm9MlnaKuXdh98AjzTi0Nz0kxKxjIsWE1pFceaRHNuwvGlnLf85sBGNo7j8ryHvzviu30yQ+8fmlBDt2yMtgXnDslLzsjah6VPvmBboGZI5p27eTnZDJrZJ8mgR5qqZUW5FBakMN7NcfP/D1zcKD1V1sXCIfyotxwSzq0T3p07UL34F9+j9xMSvKywu8tUmRAlvXIDX8SyM5MZ2jv49t6teYjT/IL7a/Crl3Ccw4BnNq/R/h26LXLiwOt8dwu6dQdaQwHYuTrhWoY3synjchtQs8VKfRag0ua/90L7RMvof3SPSfQIu9XmEPPvMC+jf19DtWfnRGooaJnN7Iy0hlYHN2f3zUrg65Z0RHWLSuDbhHLCnIDXTW987PZeyhwVniP3OPdN0Uxn9TKenh/mijulhX+WXbvndlkfb/C3HC3UJ/u2Xx2XFnUOoDSHjnsqD3EwA48iO77QPeaMCeZzh5Swkd10a2GX144mjuXbeJTo/tyx982Rq37w9VnMLqsgO8/eXyo5T9V9uO0gYUcOnKUx1bt4PVtteF1ob/5pV+fzPR/bdpKAvjpvJF8+/F14W37FeZwoP4oH9V5T3Nw+YQBTZbdMK2C2/9vY/j2RZX9uGvZJgaVdKNPfg6PfvVMnt9Y4znBUFoLn83PPbknN0yr4MzBReHt5o0tpbq2nq9MPn4AKbJx/vg1E7ntL29x6elN63zqa2dx3UOr2PxhIKDN4MqJ5dQ3NNK3IIeTenbjhXc+5MuTog9OzR3Tl8dW7eDCyuN/eAW5Xfjep4YzbVgvz9rT04wfXzCCiSc1/fjfnMsnDGB/fYNnP/y/nDOY/fVHmTOqD/sONXDnssAnm9kjezfp5nn6+knhE9fuuvRUeuc3/ef75NfO4h+bd8dV139eeRqZHt0+3zv/FAYFJ3JryW8uGcu6HXuZcUpvavYfpqhbfMPwLj9jAAcOH+XLk7yPS8DxQD/35J7cOH0Il59RHlV3Rhx9Jg99ZUKTqTjyczL5/qeGM7WZn29b/O/8CdQeiv57+uo5gzHD8/cU4M5LxvL46h0MjWkEJFJcp/53hESc+v/WB/uYefsLcW/fIzez2VBLlC2L5nD+b14Idy+EloXEToYVO0FY7AGWB196LyrsPzW6L78JHizymlgr8vF/fWMnX/ntCqae3JP7rzjNc/uRpfk8+bWzmtQXOXFXWw8mLly8loeCH59Dj59754usqdrL49dMZEy/glafY+T3nwm3yuN5/bE/XMpHdQ2s/M60Jq0uv5hzxwtsqN7Hk9eexUiP/uFUN+zWv3CooZE3fjiD3C6+b2t2mI4+9T9p2hLmAN8PHvlPlLH9CzyXf33aEM+DMbF+ffGY8O2rzx7MuAE9mmwT+9E8NLIiUqif9Edzo9/fuAE9SLPjozR+dEFgKp54aoPA+2hPa+LzwRbK1JN7MnlIOydhC7YzTitvuk+8fO9Tp5CXlRH+SO9Hob7cT+rw2x/OPYX8nEyyMtJb31g8+fbf4LFWJkOInOY1ZO6YUsp65PDZe15JSA3ThvViVUR3SMjUYb1458ezWpyaNrbVuWCW97jU0B/3ZRP68+MLvId/Lf362Z7LC7t2YfPPjr/O5RMGhLtX4pk29/ppFVw/raLV7WKNKM1vtlXd1k+E919xWlzbXTC2lAvGlrbpuTub0L5pqcsqlV1Y2Y8LK/sluwxf820L/Y5nN7a4fuqw6D7A/GDLrXd+y2OoY7V0FuCwPnmtdh+UFjR9vdBQs3hU9Ay0kEeVtvw6bTU6WLfXULYO0caQmhKs6+M6AaQzCB2cjbc/WiSWb1voy95qeS7u2z43OmqO7VdvmQoEAvb5m6bwlw2BK+205unrJ7G2ai9DeuXhXGA4U6NzfLC3nlFlBUwYVMRHdQ3h4WyRlt8yNWroU2hZblb8u/2MwUU8+82zmxzhP1GLv3omL2ys4ez2dom0VRtb5r+4cBQ3zRgaNRwv1d0y+2SuOLM87tFGIrF8G+itTT/ZJSMtfJksICoY+hflMqxPy8O3QrIy0jmtvOlcFqEhV7ldMpo9gNPT4w/Ta1lrBrUwVKy90tOMcz7GU9bzg0PF4r3sVlZGeni41ydFRnoa/Vs4CUekNb4NdK85z0MuGd8faLlRGLvuxulD+P2r23j0q2fy2KodlAaHvHVmv/3i+LgPcCbbv14U+MTU3FmXInLifBvox1pI69iREV7dt7GPzsvO5JWFgW6Za6acdKLlfSzaPYIkCYq6ZfGlZiYqEpHESMlAD60aXx64qrjXSR2hEQW9u2dTe+gI5w0/sZMNvnHeEF7YWNP6hp3czFN6e560IiKdn48DvfVtQqfijikraLIuFPpDe+fxX18cf8L1XDe1guumtn2IX2dz7+Xjkl2CiLSTPzpgPbQ0Dj00V0JoYn6vA00u2OnyCR3yKyIpyLctdK+LPT9x7US6ZKRxcu/AgbcrJ5Zz3vBenqMlQg9XnotIqvBtoG/dXddk2aiYrhUza3boW2gYY+TMayIifubbQD9RZw4u4rvnD4+abU9ExM8+sYFuZnxRw+hEJIX49qBorPNP4DqWIiKpICVa6O29+K+ISCpJmRa6iMgnnQJdRCRF+DLQ6xsak12CiEin48tA37XvcLJLEBHpdHwZ6C1NzCUi8knl+0A/Z6h/ppAVEelIvgz0yPb51GEnNu2tiEiq8GWgR860qCvgiIgE+DPQI5rop/bv0fyGIiKfID4NdB0UFRGJ5ctAV56LiDTly0BXC11EpClfBrryXESkKV8Gutfl50REPuniCnQzm2lmb5vZJjNb4LE+38yeNLM1ZrbBzK5MfKnHPfDiex359CIivtRqoJtZOnAXMAsYDlxiZsNjNrsGeMM5Nxo4B/ilmXXYxTrf2bm/o55aRMS34mmhjwc2Oec2O+eOAA8Dc2O2cUCemRnQDdgDHE1opRFK8rI66qlFRHwrnkAvBbZH3K8KLot0JzAMqAbWAdc7547FPpGZzTezFWa2oqampp0lw0WV/dr9WBGRVBVPoJvHstijkjOA1UBfYAxwp5k1OSffOXefc67SOVdZUtL+SbXMqyIRkU+4eAK9CohsEpcRaIlHuhJY7AI2Ae8BJyemxKZCg1wWzOqwlxAR8Z14Av01oMLMBgYPdF4MPBGzzTZgKoCZ9QKGApsTWWik0MeDacN6dtRLiIj4TkZrGzjnjprZtcAzQDrwgHNug5ldHVx/L/Aj4EEzW0egi+Zm59yHHVW0C49DV9+LiEhIq4EO4JxbAiyJWXZvxO1qYHpiS2tdmvJcRCTMl2eK3vv3QG+OzhcVETnOl4H+5vv7AGg8pkgXEQnxZaCLiEhTCnQRkRShQBcRSRG+DnTNoisicpy/A13jXEREwvwd6MpzEZEwXwe6iIgc5+tAVwtdROQ4fwe6+tBFRML8HejKcxGRMF8Het+CnGSXICLSafg60Au7dth1qEVEfMfXgS4iIscp0EVEUoQCXUQkRSjQRURShAJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURShG8DvUduZrJLEBHpVHwZ6F27pPOZU8uSXYaISKfiy0B3gCW7CBGRTsafge7AlOgiIlF8GegApkQXEYniy0DXpedERJryZ6A79aGLiMTyZ6CDEl1EJIYvAx0HpkQXEYniy0B3OI1yERGJ4ctAB/W4iIjE8mWgOw1yERFpwp+Bjk4sEhGJFVegm9lMM3vbzDaZ2YJmtjnHzFab2QYz+3tiy4zmnNNBURGRGBmtbWBm6cBdwHlAFfCamT3hnHsjYpsC4G5gpnNum5n17KB6AbXQRUS8xNNCHw9scs5tds4dAR4G5sZscymw2Dm3DcA5tyuxZUbTiUUiIk3FE+ilwPaI+1XBZZGGAD3M7DkzW2lmX/B6IjObb2YrzGxFTU1N+yo+/mQn9ngRkRQTT6B7JWfsOJMMYBwwB5gB3GpmQ5o8yLn7nHOVzrnKkpKSNhcrIiLNa7UPnUCLvF/E/TKg2mObD51zB4GDZvY8MBp4JyFVRnDBMYtqn4uIRIunhf4aUGFmA82sC3Ax8ETMNn8CJplZhpnlAqcDbya21IDQGHT1uIiIRGu1he6cO2pm1wLPAOnAA865DWZ2dXD9vc65N83sL8Ba4BjwH8659R1RcKivR8MWRUSixdPlgnNuCbAkZtm9Mfd/AfwicaU1WwugFrqISCxfnikK6kMXEYnlu0DXNC4iIt78F+g6KCoi4sl/gU6oD12JLiISyX+Brj4XERFPvgv0EDXQRUSi+TfQNc5FRCSK7wJdXS4iIt78F+joxCIRES/+C/TQsMXkliEi0un4L9CD39VCFxGJ5r9AD0+fq0QXEYnku0APUQtdRCSa7wJdg1xERLz5L9CV6CIinnwX6IQn51Kfi4hIJN8FengcepLrEBHpbPwX6Jo+V0TEk+8CPUR5LiISzXeBrmOiIiLe/BfoThe4EBHx4r9AD35XnouIRPNfoGtyLhERT/4LdDTMRUTEi+8CPURxLiISzX+BrmEuIiKefBfoOigqIuLNf4EePiiqRBcRieS/QNc1RUVEPPkv0DVsUUTEk+8CPUQtdBGRaL4LdA1yERHx5r9A10WiRUQ8+TDQgzeU5yIiUXwX6CHKcxGRaL4LdKdrioqIePJdoIcozkVEovku0J3GuYiIeIor0M1sppm9bWabzGxBC9udZmaNZva5xJUYTReJFhHx1mqgm1k6cBcwCxgOXGJmw5vZ7ufAM4kuMpIm5xIR8RZPC308sMk5t9k5dwR4GJjrsd3XgEeBXQmsrwmNQxcR8RZPoJcC2yPuVwWXhZlZKTAPuLelJzKz+Wa2wsxW1NTUtLVWQC10EZHmxBPoXtEZe2TyduBm51xjS0/knLvPOVfpnKssKSmJs0QREYlHRhzbVAH9Iu6XAdUx21QCDwfHhhcDs83sqHPu8UQUGclpkIuIiKd4Av01oMLMBgI7gIuBSyM3cM4NDN02sweBpzoizIOvFnqdjnl6ERGfajXQnXNHzexaAqNX0oEHnHMbzOzq4PoW+80TTfOhi4h4i6eFjnNuCbAkZplnkDvnrjjxslqoJfhdDXQRkWj+O1NU1xQVEfHku0APUQtdRCSa7wJdc7mIiHjzX6DroKiIiCf/BroSXUQkiv8CHV2DTkTEi+8CPUQtdBGRaL4LdJ36LyLizXeBHqIGuohINN8Fui4SLSLizX+BHpqcK8l1iIh0Nv4LdA1bFBHx5LtAD1Ggi4hE812ga5CLiIg3/wW6LhItIuLJf4EeuqE8FxGJ4r9A1+RcIiKefBfouqaoiIg3HwZ6gOJcRCSa7wJdc7mIiHjzX6AHv6vHRUQkmv8CXReJFhHx5MNADx0UTXIhIiKdjP8CPfhdeS4iEs13gR6mRBcRieK7QNcoFxERb/4LdDSXi4iIF98FOpoPXUTEk+8CXQdFRUS8+S/QdU1RERFPvgv0EOW5iEg03wW60zWLREQ8+S/QNR+6iIgn/wV68Lu6XEREovkv0J3GuYiIePFfoAe/q4UuIhLNd4EeojwXEYkWV6Cb2Uwze9vMNpnZAo/1nzeztcGvl81sdOJLDdIgFxERT60GupmlA3cBs4DhwCVmNjxms/eAs51zo4AfAfclutAQp4tEi4h4yohjm/HAJufcZgAzexiYC7wR2sA593LE9v8AyhJZZCQNWxSRSA0NDVRVVVFfX5/sUhIqOzubsrIyMjMz435MPIFeCmyPuF8FnN7C9l8CnvZaYWbzgfkA/fv3j7PEaE6Tc4lIhKqqKvLy8igvL0+ZT+7OOXbv3k1VVRUDBw6M+3Hx9KF77SHPnmwzm0Ig0G9upsj7nHOVzrnKkpKSuIv0emFNnysiAPX19RQVFaVMmEOgS7moqKjNnzriaaFXAf0i7pcB1R4FjAL+A5jlnNvdpiraIYV+diJyglIpzEPa857iaaG/BlSY2UAz6wJcDDwR88L9gcXA5c65d9pcRRs4XbJIRMRTq4HunDsKXAs8A7wJPOKc22BmV5vZ1cHNvgsUAXeb2WozW9FRBSvORaQzqa2t5e67727XY2+//Xbq6uoSVktc49Cdc0ucc0Occ4Odcz8JLrvXOXdv8PaXnXM9nHNjgl+VCauwSS2B7yn4CUtEfKgzBXo8feidjK4pKiLefvDkBt6o3pfQ5xzetzvf+9Qpza5fsGAB7777LmPGjOG8886jZ8+ePPLIIxw+fJh58+bxgx/8gIMHD3LRRRdRVVVFY2Mjt956Kzt37qS6upopU6ZQXFzMsmXLTrhW3wW6Wugi0pksWrSI9evXs3r1apYuXcof//hHli9fjnOOT3/60zz//PPU1NTQt29f/vznPwOwd+9e8vPz+dWvfsWyZcsoLi5OSC2+C/QQBbqIxGqpJf1xWLp0KUuXLmXs2LEAHDhwgI0bNzJp0iRuvPFGbr75Zs4//3wmTZrUIa/vu0DXQVER6ayccyxcuJCrrrqqybqVK1eyZMkSFi5cyPTp0/nud7+b8Nf33WyLx0/9VxNdRJIvLy+P/fv3AzBjxgweeOABDhw4AMCOHTvYtWsX1dXV5Obmctlll3HjjTfy+uuvN3lsIviwhR6anCvJhYiIAEVFRUycOJERI0Ywa9YsLr30Us444wwAunXrxu9+9zs2bdrETTfdRFpaGpmZmdxzzz0AzJ8/n1mzZtGnT5+EHBS1ZJ2oU1lZ6VasaPtw9ZVb9/DAi1v4zvnD6JOf0wGViYifvPnmmwwbNizZZXQIr/dmZiubGxruuxb6uAGFjBtQmOwyREQ6Hd/1oYuIiDcFuoj4XirO8dSe96RAFxFfy87OZvfu3SkV6qH50LOzs9v0ON/1oYuIRCorK6Oqqoqamppkl5JQoSsWtYUCXUR8LTMzs01X9Ull6nIREUkRCnQRkRShQBcRSRFJO1PUzGqAre18eDHwYQLL6Uh+qVV1Jp5falWdidXRdQ5wzpV4rUhaoJ8IM1vRkVdFSiS/1Ko6E88vtarOxEpmnepyERFJEQp0EZEU4ddAvy/ZBbSBX2pVnYnnl1pVZ2IlrU5f9qGLiEhTfm2hi4hIDAW6iEiK8F2gm9lMM3vbzDaZ2YJOUM8WM1tnZqvNbEVwWaGZ/dXMNga/94jYfmGw9rfNbEYH1vWAme0ys/URy9pcl5mNC76/TWZ2h1niL/7XTK3fN7Mdwf262sxmJ7tWM+tnZsvM7E0z22Bm1weXd6r92kKdnWqfmlm2mS03szXBOn8QXN7Z9mdzdXaq/QkEpmn0yxeQDrwLDAK6AGuA4UmuaQtQHLPsNmBB8PYC4OfB28ODNWcBA4PvJb2D6poMnAqsP5G6gOXAGYABTwOzPqZavw/c6LFt0moF+gCnBm/nAe8E6+lU+7WFOjvVPg0+Z7fg7UzgVWBCJ9yfzdXZqfanc853LfTxwCbn3Gbn3BHgYWBukmvyMhf4r+Dt/wIuiFj+sHPusHPuPWATgfeUcM6554E9J1KXmfUBujvnXnGB38bfRjymo2ttTtJqdc6975x7PXh7P/AmUEon268t1NmcZNXpnHMHgnczg1+Ozrc/m6uzOUn7HfVboJcC2yPuV9HyL+rHwQFLzWylmc0PLuvlnHsfAn9cQM/g8mTX39a6SoO3Y5d/XK41s7XBLpnQx+5OUauZlQNjCbTWOu1+jakTOtk+NbN0M1sN7AL+6pzrlPuzmTqhk+1PvwW6V39TssddTnTOnQrMAq4xs8ktbNsZ64fm60pmvfcAg4ExwPvAL4PLk16rmXUDHgVucM7ta2nTZmr6WGr1qLPT7VPnXKNzbgxQRqAVO6KFzTtbnZ1uf/ot0KuAfhH3y4DqJNUCgHOuOvh9F/AYgS6UncGPVwS/7wpunuz621pXVfB27PIO55zbGfwjOgb8O8e7ppJaq5llEgjJ3zvnFgcXd7r96lVnZ92nwdpqgeeAmXTC/elVZ2fcn34L9NeACjMbaGZdgIuBJ5JVjJl1NbO80G1gOrA+WNM/Bzf7Z+BPwdtPABebWZaZDQQqCBwk+bi0qa7gx939ZjYheDT+CxGP6VChP+igeQT2a1JrDT7v/cCbzrlfRazqVPu1uTo72z41sxIzKwjezgGmAW/R+fanZ52dbX8C/hrlEjiOwGwCR+3fBb6d5FoGETiavQbYEKoHKAL+BmwMfi+MeMy3g7W/TQeMGIl4nYcIfAxsINAy+FJ76gIqg7+o7wJ3Ejy7+GOo9b+BdcBaAn8gfZJdK3AWgY/Ia4HVwa/ZnW2/tlBnp9qnwChgVbCe9cB32/v3k6Q6O9X+dM7p1H8RkVThty4XERFphgJdRCRFKNBFRFKEAl1EJEUo0EVEUoQCXUQkRSjQRURSxP8HAmDm7FBOiwEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#pyplot.plot(loss_list, label='train')\n",
    "pyplot.plot(acc_list, label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/silvio/git/datasets/bees/wingsEval\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "\n",
    "# Percorre os arquivos no diretório de imagens para treinamento\n",
    "def create_test_data(path):\n",
    "    for p in os.listdir(path):\n",
    "\n",
    "        # categoria da imagem é definida pelo nome do arquivo\n",
    "        category = p.split(\" \")[0]\n",
    "        \n",
    "        # Abre a imagem usando opencv em escala de cinza\n",
    "        img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Redimensionamento para 80 x 80 pixels\n",
    "        new_img_array = cv2.resize(img_array, dsize=(320, 320))\n",
    "        \n",
    "        X.append(new_img_array)\n",
    "        y.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1737, 320, 320)\n",
      "(1737,)\n",
      "(1737, 320, 320, 1)\n",
      "(1737,)\n"
     ]
    }
   ],
   "source": [
    "#path= \"../dogsCatsDB/train\"\n",
    "path=\"/home/silvio/git/datasets/bees/wingsEval\"\n",
    "\n",
    "create_test_data(path)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)\n",
    "\n",
    "X = np.array(X).reshape(-1, 320,320,1)\n",
    "y = np.array(y)\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_test_data_wings(path):\n",
    "        Xl = []\n",
    "        yl = []\n",
    "        \n",
    "        for p in os.listdir(path):\n",
    "\n",
    "            # categoria da imagem é definida pelo nome do arquivo\n",
    "            category = p.split(\" \")[0]\n",
    "        \n",
    "            # Abre a imagem usando opencv em escala de cinza\n",
    "            img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Redimensionamento para 80 x 80 pixels\n",
    "            new_img_array = cv2.resize(img_array, dsize=(320, 320))\n",
    "        \n",
    "            Xl.append(new_img_array)\n",
    "            yl.append(category)\n",
    "            le = LabelEncoder()\n",
    "            yll= le.fit_transform(yl)\n",
    "\n",
    "\n",
    "            #print(yll)\n",
    "            #yl = torch.nn.functional.one_hot(yl)\n",
    "        \n",
    "        return(Xl, yll)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wingsDataset(Dataset):\n",
    "    #Xl = []\n",
    "    #yl = []\n",
    "    # Percorre os arquivos no diretório de imagens para treinamento\n",
    "    def create_test_data_wings(self, path):\n",
    "        Xl = []\n",
    "        yl = []\n",
    "        \n",
    "        for p in os.listdir(path):\n",
    "\n",
    "            # categoria da imagem é definida pelo nome do arquivo\n",
    "            category = p.split(\" \")[0]\n",
    "        \n",
    "            # Abre a imagem usando opencv em escala de cinza\n",
    "            img_array = cv2.imread(os.path.join(path,p),cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Redimensionamento para 80 x 80 pixels\n",
    "            new_img_array = cv2.resize(img_array, dsize=(320, 320))\n",
    "        \n",
    "            Xl.append(new_img_array)\n",
    "            yl.append(category)\n",
    "            \n",
    "            yll= le.fit_transform(yl)\n",
    "            #print(yll)\n",
    "            #yl = torch.nn.functional.one_hot(yl)\n",
    "        \n",
    "        return(Xl, yll)\n",
    "    \n",
    "    def __init__(self, path):\n",
    "\n",
    "\n",
    "        #self.X = df.values[:, :-1]\n",
    "        #self.y = df.values[:, -1]\n",
    "        \n",
    "        #self.X = self.X.astype('float32')\n",
    "\n",
    "        #sc2 = StandardScaler()\n",
    "        #self.X = sc2.fit_transform(self.X)\n",
    "        \n",
    "        #self.y = LabelEncoder().fit_transform(self.y)\n",
    "        #self.y = self.y.astype('float32')\n",
    "        #self.y = self.y.reshape((len(self.y), 1))\n",
    "        #path=\"/home/silvio/git/datasets/bees/wingsEval\"\n",
    "\n",
    "        Xl, yl = create_test_data_wings(path)\n",
    "\n",
    "        \n",
    "        Xl=np.array(Xl)\n",
    "        Xl = np.array(Xl).reshape(-1, 320,320,1)\n",
    "        \n",
    "        self.X = Tensor(Xl)\n",
    "        self.y = Tensor(np.array(yl))\n",
    "        \n",
    "        \n",
    "        print(self.X.shape)\n",
    "        self.X = self.X.permute(0, 3, 1, 2) # from NHWC to NCHW\n",
    "        print(self.X.shape)\n",
    "        #print(self.y.shape)\n",
    "        #self.y = self.y.permute(0, 3, 1, 2) # from NHWC to NCHW\n",
    "        print(self.y.shape)\n",
    "            \n",
    "        #print(np.array(self.X).shape)\n",
    "        #print(np.array(self.y).shape)\n",
    "\n",
    "        #self.X = np.array(self.X).reshape(-1, 320,320,1)\n",
    "        #self.y = np.array(self.y)\n",
    "\n",
    "        #print(\"X \", np.array(self.X).shape)\n",
    "        #print(np.array(self.y).shape)\n",
    " \n",
    "    # quantas linhas tem no dataset?\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    # obtem uma linha do dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]\n",
    " \n",
    "    # retorna base para treino e teste\n",
    "    def get_splits(self, n_test=0.33):\n",
    "        test_size = round(n_test * len(self.X))\n",
    "        train_size = len(self.X) - test_size\n",
    "        return random_split(self, [train_size, test_size])\n",
    "    \n",
    "def prepare_data(path):\n",
    "    # Carrega Dataset\n",
    "    dataset = wingsDataset(path)\n",
    "    # realiza split\n",
    "    train, test = dataset.get_splits()\n",
    "   \n",
    "    # monta data loaders\n",
    "    train_dl = DataLoader(train, batch_size=1024, shuffle=True)\n",
    "    #test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    test_dl = DataLoader(test, batch_size=1024, shuffle=False)\n",
    "    \n",
    "    return train_dl, test_dl\n",
    "\n",
    "class MLP(Module):\n",
    "    # Elementos do modelo\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        # camada de entrada\n",
    "        self.hidden1 = Linear(n_inputs, 64)\n",
    "        # Inicialização da camada de entrada\n",
    "        #kaiming_uniform_(self.hidden1.weight, nonlinearity='relu')\n",
    "        # Ativação da camada de entrada\n",
    "        self.act1 = ReLU()\n",
    "        # segunda camada , entrada tem que ser do mesmo tamanho da saida da camada 1\n",
    "        self.hidden2 = Linear(64, 8)\n",
    "        # Inicialização da camada\n",
    "        #kaiming_uniform_(self.hidden2.weight, nonlinearity='relu')\n",
    "        # Ativação da camada\n",
    "        self.act2 = ReLU()\n",
    "        self.hidden3 = Linear(8, 8)\n",
    "        self.act3 = ReLU()\n",
    "        \n",
    "        # camada de saída\n",
    "        self.hidden4 = Linear(8, 1)\n",
    "        # Inicialização da camada\n",
    "        #xavier_uniform_(self.hidden3.weight)\n",
    "        # Ativação da camada\n",
    "        self.act4 = Sigmoid()\n",
    " \n",
    "    # propagação da entrada pelas camadas\n",
    "    def forward(self, X):\n",
    "        # entrada para primeira camada escondida\n",
    "        X = self.hidden1(X)\n",
    "        X = self.act1(X)\n",
    "        # segunda camada escondida\n",
    "        X = self.hidden2(X)\n",
    "        X = self.act2(X)\n",
    "        # terceira camada escondida\n",
    "        X = self.hidden3(X)\n",
    "        X = self.act3(X)\n",
    "        # camada de saida\n",
    "        X = self.hidden4(X)\n",
    "        X = self.act4(X)\n",
    "        return X\n",
    "\n",
    "\n",
    "\n",
    "#logDir = \"/home/silvio/tb/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/train/\"\n",
    "\n",
    "#writerTrain = SummaryWriter(logDir)\n",
    "#logDir = \"/home/silvio/tb/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/test/\"\n",
    "#writerTest = SummaryWriter(logDir)\n",
    "\n",
    "def train_model(train_dl, model):\n",
    "    # define loss\n",
    "    criterion = BCELoss()\n",
    "    # define otimizador\n",
    "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # loop por épocas\n",
    "    for epoch in range(200):\n",
    "        # Loop em conjunto de mini-batches\n",
    "        for i, (inputs, targets) in enumerate(train_dl):\n",
    "            print(\"inputs.shape \",inputs.shape)\n",
    "            print(\"targets \", targets)\n",
    "            # zera os gradientes do batches\n",
    "            optimizer.zero_grad()\n",
    "            # predição do batch\n",
    "            yhat = model(inputs)\n",
    "            # calcula loss\n",
    "            loss = criterion(yhat, targets)\n",
    "            \n",
    "            \n",
    "            #print(yhat.detach().numpy(), targets.detach().numpy())\n",
    "            #print(accuracy_score(yhat.detach().numpy(), targets.detach().numpy()))\n",
    "            \n",
    "            #print(type(yhat), type(targets))\n",
    "            #print()\n",
    "            \n",
    "            #writer.add_scalar('Loss ', loss.detach().numpy(),epoch)    \n",
    "            \n",
    "            # Retroprapagando erros \n",
    "            loss.backward()\n",
    "            # atualiza pesos (otimização )\n",
    "            optimizer.step()\n",
    "            #print(loss)\n",
    "            \n",
    "            acctest = evaluate_model(test_dl, model)\n",
    "            acctrain = evaluate_model(train_dl, model)\n",
    "            #writer.add_scalar('epoch_loss', loss.detach().numpy(), epoch)\n",
    "            #writerTrain.add_scalar('epoch_accuracy', acctrain, epoch)\n",
    "            #writer.add_scalar('epoch_accuracy', acctest, epoch)\n",
    "            #writerTrain.add_scalar('epoch_loss', loss.detach().numpy(), epoch)\n",
    "            #writerTest.add_scalar('epoch_accuracy', acctest, epoch)\n",
    "            \n",
    "            print(\"epoca \" , epoch, \" loss \", loss.detach().numpy() , \" acctest \", acctest,\" acctrain \", acctrain)\n",
    "\n",
    "\n",
    "def evaluate_model(test_dl, model):\n",
    "    # Cria lista de preditos e reais\n",
    "    predictions, actuals = list(), list()\n",
    "\n",
    "    # percorre lista do dataloader de test\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        # realiza predição\n",
    "        yhat = model(inputs)\n",
    "        # cria numpy array\n",
    "        yhat = yhat.detach().numpy()\n",
    "        actual = targets.numpy()\n",
    "        actual = actual.reshape((len(actual), 1))\n",
    "        # round valores da classe\n",
    "        yhat = yhat.round()\n",
    "        # armazena\n",
    "        predictions.append(yhat)\n",
    "        actuals.append(actual)\n",
    "        \n",
    "    predictions, actuals = vstack(predictions), vstack(actuals)\n",
    "    # usa sklearn para calcular acurácia\n",
    "    acc = accuracy_score(actuals, predictions)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/silvio/git/datasets/bees/wingsEvalT': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/silvio/git/datasets/bees/wingsEvalT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 320, 320, 1])\n",
      "torch.Size([10, 1, 320, 320])\n",
      "torch.Size([10])\n",
      "(10, 1, 320, 320)\n",
      "(10,)\n",
      "X  (10, 320, 320, 1)\n",
      "(10,)\n",
      "7 3\n"
     ]
    }
   ],
   "source": [
    "# Prepara os dados\n",
    "path = '/home/silvio/dataset/bees/wingsEvalT'\n",
    "\n",
    "train_dl, test_dl = prepare_data(path)\n",
    "\n",
    "print(len(train_dl.dataset), len(test_dl.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  torch.Size([7, 320, 320, 1])\n",
      "targets  tensor([0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 5, 5], expected input[7, 320, 320, 1] to have 1 channels, but got 320 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-115e080bdce8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# treina o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-92-7a4266a142b7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, model)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# predição do batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;31m# calcula loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9f8de5a4cc3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 5, 5], expected input[7, 320, 320, 1] to have 1 channels, but got 320 channels instead"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "# criar modelo\n",
    "#model = MLP(8)\n",
    "model = ConvNet()\n",
    "# treina o modelo\n",
    "train_model(train_dl, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape  torch.Size([7, 320, 320, 1])\n",
      "targets  tensor([0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 5, 5], expected input[7, 320, 320, 1] to have 1 channels, but got 320 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-246c74203b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# treina o modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# avalia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-7a4266a142b7>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_dl, model)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# predição do batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m             \u001b[0;31m# calcula loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-9f8de5a4cc3e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/natosafe/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 5, 5], expected input[7, 320, 320, 1] to have 1 channels, but got 320 channels instead"
     ]
    }
   ],
   "source": [
    "\n",
    "# avalia\n",
    "acc = evaluate_model(test_dl, model)\n",
    "print('Acuracia: %.3f' % acc)\n",
    "# testa uma predição\n",
    "#row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "#yhat = predict(row, model)\n",
    "#print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
